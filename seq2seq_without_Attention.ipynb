{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvAdLOaVYwyYSUK25nPnpV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aman9213/DL_assignment3/blob/main/seq2seq_without_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMpYfXaFYmni"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from torch.utils.data import DataLoader,Dataset \n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vLcvQ9b6eIhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d046c0e-5f91-47ef-a523-6fd7f539d256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPSuUeiJtXpO",
        "outputId": "8fe02e6b-8e74-41b8-b16a-723651dfe970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/hin'\n",
        "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "print(csv_files)\n",
        "test_path=csv_files[0]\n",
        "train_path=csv_files[2]\n",
        "valid_path=csv_files[1]\n",
        "train_data=pd.read_csv(train_path)\n",
        "valid_data=pd.read_csv(valid_path)\n",
        "test_data=pd.read_csv(test_path)\n",
        "display((valid_data))\n",
        "train_data_matrix=train_data.to_numpy()\n",
        "valid_data_matrix=valid_data.to_numpy()\n",
        "test_data_matrix=test_data.to_numpy()\n",
        "# print(train_data_matrix[:,1])\n",
        "print(valid_data_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ayBGC6kkug2r",
        "outputId": "1615d203-7e62-4c54-9c37-80388c4f1617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/hin/hin_test.csv', '/content/drive/MyDrive/hin/hin_valid.csv', '/content/drive/MyDrive/hin/hin_train.csv']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         jaisawal       जयसवाल\n",
              "0           bajai         बजाई\n",
              "1       sanghthan        संघठन\n",
              "2         haiwaan        हैवान\n",
              "3         nilgiri      नीलगिरि\n",
              "4       drutgrami  द्रुतग्रामी\n",
              "...           ...          ...\n",
              "4090     paranshu       परांशु\n",
              "4091    romanchit     रोमांचित\n",
              "4092  ekamreshwar  एकाम्रेश्वर\n",
              "4093    bluetooth    ब्ल्यूटूथ\n",
              "4094    govindram   गोविंद्राम\n",
              "\n",
              "[4095 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08ba32fd-4342-4c39-ad6f-7436f46a6761\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jaisawal</th>\n",
              "      <th>जयसवाल</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bajai</td>\n",
              "      <td>बजाई</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sanghthan</td>\n",
              "      <td>संघठन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>haiwaan</td>\n",
              "      <td>हैवान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nilgiri</td>\n",
              "      <td>नीलगिरि</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drutgrami</td>\n",
              "      <td>द्रुतग्रामी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4090</th>\n",
              "      <td>paranshu</td>\n",
              "      <td>परांशु</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>romanchit</td>\n",
              "      <td>रोमांचित</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>ekamreshwar</td>\n",
              "      <td>एकाम्रेश्वर</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>bluetooth</td>\n",
              "      <td>ब्ल्यूटूथ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>govindram</td>\n",
              "      <td>गोविंद्राम</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4095 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08ba32fd-4342-4c39-ad6f-7436f46a6761')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08ba32fd-4342-4c39-ad6f-7436f46a6761 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08ba32fd-4342-4c39-ad6f-7436f46a6761');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4095, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(source,target,path):\n",
        "    # Load the CSV data using pandas\n",
        "\n",
        "    # data = pd.read_csv('data.csv')\n",
        "    data=pd.read_csv(path)\n",
        "    # Convert the data to lowercase\n",
        "    data[source] = data[source].str.lower()\n",
        "\n",
        "    # Clean and normalize Hindi text\n",
        "    def clean_text(text):\n",
        "        # Remove punctuations and digits\n",
        "        text = re.sub(r'[^\\u0900-\\u097F\\s]', '', text)\n",
        "        text = re.sub(r'[\\d]', '', text)\n",
        "\n",
        "        # Normalize text\n",
        "        text = unicodedata.normalize('NFD', text)\n",
        "        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')\n",
        "        text = unicodedata.normalize('NFC', text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    data[target] = data[target].apply(clean_text)\n",
        "    # print(train_data)\n",
        "    # Tokenize the data\n",
        "    source_chars = set()\n",
        "    target_chars = set()\n",
        "\n",
        "    for src, targ in zip(data[source],data[target]):\n",
        "        source_chars.update(src)\n",
        "        target_chars.update(targ)\n",
        "\n",
        "    source_chars = sorted(list(source_chars))\n",
        "    target_chars = sorted(list(target_chars))\n",
        "    # print(target_chars,source_chars )\n",
        "    source_char_to_id = {char: i for i, char in enumerate(source_chars)}\n",
        "    target_char_to_id = {char: i for i, char in enumerate(target_chars)}\n",
        "    source_id_to_char={i:char for i,char in enumerate(target_chars)}\n",
        "    target_id_to_char={i:char for i,char in enumerate(target_chars)}\n",
        "#     print(source_char_to_id,target_char_to_id)\n",
        "    # Add padding, start-of-sequence and end-of-sequence tokens\n",
        "    source_char_to_id['<PAD>'] = len(source_char_to_id)\n",
        "    target_char_to_id['<PAD>'] = len(target_char_to_id)\n",
        "\n",
        "    source_char_to_id['<SOS>'] = len(source_char_to_id)\n",
        "    target_char_to_id['<SOS>'] = len(target_char_to_id)\n",
        "\n",
        "    source_char_to_id['<EOS>'] = len(source_char_to_id)\n",
        "    target_char_to_id['<EOS>'] = len(target_char_to_id)\n",
        "\n",
        "    # Convert characters to numerical values\n",
        "    data_numerical = []\n",
        "\n",
        "\n",
        "    for src, targ in zip(data[source], data[target]):\n",
        "        \n",
        "        source_numerical = [source_char_to_id[char] for char in src]\n",
        "        target_numerical = [target_char_to_id[char] for char in targ]\n",
        "        source_numerical=[source_char_to_id['<SOS>']]+source_numerical+[source_char_to_id['<EOS>']]+[source_char_to_id['<PAD>']]*(28-len(src)-2)\n",
        "        target_numerical=[target_char_to_id['<SOS>']]+target_numerical+[target_char_to_id['<EOS>']]+[target_char_to_id['<PAD>']]*(20-len(targ)-2)\n",
        "        \n",
        "        data_numerical.append([source_numerical, target_numerical])\n",
        "    return data_numerical,target_id_to_char,source_id_to_char"
      ],
      "metadata": {
        "id": "gJtRyjUjuvUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_numerical,_,_=tokenize('shastragaar','शस्त्रागार',train_path)\n",
        "valid_data_numerical,_,_=tokenize('jaisawal','जयसवाल',valid_path)\n",
        "test_data_numerical,target_id_to_char,source_id_to_char=tokenize('thermax','थरमैक्स',test_path)\n"
      ],
      "metadata": {
        "id": "-9m6SSWcu9aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  test_data_numerical=tokenize('thermax','थरमैक्स',test_path)\n",
        "class AksharantarDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "    \n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        source, target = self.data[index]\n",
        "        source_tensor = torch.tensor(source, dtype=torch.long)\n",
        "        target_tensor = torch.tensor(target, dtype=torch.long)\n",
        "#         print('--->insidedataloader ',index,source_tensor.shape,target_tensor.shape)\n",
        "        \n",
        "        return source_tensor, target_tensor\n"
      ],
      "metadata": {
        "id": "lKSTqi8GvCP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=AksharantarDataset(train_data_numerical)\n",
        "valid_set=AksharantarDataset(valid_data_numerical)\n",
        "test_set=AksharantarDataset(test_data_numerical)"
      ],
      "metadata": {
        "id": "JDVtkvCZvupk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_set=DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "valid_data_set=DataLoader(valid_set, batch_size=64, shuffle=False)\n",
        "test_data_set=DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "print(len(train_data_set))\n",
        "print(len(valid_data_set))\n",
        "print(len(test_data_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd2sTFKRvylq",
        "outputId": "0e5fc554-c289-440c-bab0-f34fdad45e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n",
            "64\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_size,embedding_size,hidden_size,num_layer,dropout,input_vocab_size,bidirection,cell_type):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.cell_type=cell_type\n",
        "    #self.embedding_size = embeddings_size\n",
        "    self.bidirection=bidirection\n",
        "    self.hidden_size=hidden_size\n",
        "    self.num_layer=num_layer\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "    self.embedding=nn.Embedding(input_vocab_size,embedding_size)\n",
        "    if cell_type=='LSTM':\n",
        "      if num_layer!=1: \n",
        "        self.rnn=nn.LSTM(embedding_size,hidden_size,num_layer,dropout=dropout,bidirectional=bidirection)\n",
        "      else:\n",
        "        self.rnn=nn.LSTM(embedding_size,hidden_size,num_layer,bidirectional=bidirection)\n",
        "    elif cell_type=='GRU':\n",
        "      if num_layer!=1:\n",
        "        self.rnn=nn.GRU(embedding_size,hidden_size,num_layer,dropout=dropout,bidirectional=bidirection)\n",
        "      else:\n",
        "        self.rnn=nn.GRU(embedding_size,hidden_size,num_layer,bidirectional=bidirection)\n",
        "\n",
        "    elif cell_type=='RNN':\n",
        "      if num_layer!=1:\n",
        "        self.rnn=nn.RNN(embedding_size,hidden_size,num_layer,dropout=dropout,bidirectional=bidirection)\n",
        "      else:\n",
        "        self.rnn=nn.RNN(embedding_size,hidden_size,num_layer,bidirectional=bidirection)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "      \n",
        "    batch_size=inputs.shape[0]\n",
        "\n",
        "    if self.bidirection:\n",
        "      h0=torch.randn(2*self.num_layer,batch_size,self.hidden_size).to(device)\n",
        "      if self.cell_type=='LSTM':\n",
        "        c0=torch.randn(2*self.num_layer,batch_size,self.hidden_size).to(device)\n",
        "    else:\n",
        "      h0=torch.randn(self.num_layer,batch_size,self.hidden_size).to(device)\n",
        "      if self.cell_type=='LSTM':\n",
        "        c0=torch.randn(self.num_layer,batch_size,self.hidden_size).to(device)\n",
        "    embedding=self.dropout(self.embedding(inputs)) ### (batch,28,embedding_size)\n",
        "    embedding=torch.permute(embedding,(1,0,2))     ##(28,batch,embedding)\n",
        "    if self.cell_type=='LSTM':\n",
        "      output,(hidden,cell)=self.rnn(embedding,(h0,c0))\n",
        "      return hidden, cell\n",
        "    else:\n",
        "      output,hidden=self.rnn(embedding,h0)\n",
        "      cell=None\n",
        "      return hidden,cell\n",
        "    # print(\"CC\",output.shape,hidden.shape)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,input_size,embedding_size,hidden_size,output_vocab_size,num_layer,dropout,bidirection,cell_type):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.hidden_size=hidden_size\n",
        "    self.cell_type=cell_type\n",
        "    self.num_layer=num_layer\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "    self.embedding=nn.Embedding(output_vocab_size+3,embedding_size)       ## +3 because there are total 54+3=57 unique token\n",
        "    if cell_type=='LSTM':\n",
        "      if num_layer!=1:\n",
        "        self.rnn=nn.LSTM(embedding_size,hidden_size,num_layer,dropout=dropout,bidirectional=bidirection)\n",
        "      else:\n",
        "        self.rnn=nn.LSTM(embedding_size,hidden_size,num_layer,bidirectional=bidirection)\n",
        "\n",
        "    elif cell_type=='GRU':\n",
        "      if num_layer!=1:\n",
        "        self.rnn=nn.GRU(embedding_size,hidden_size,num_layer,dropout=dropout,bidirectional=bidirection)\n",
        "      else:\n",
        "        self.rnn=nn.GRU(embedding_size,hidden_size,num_layer,bidirectional=bidirection)\n",
        "    elif cell_type=='RNN':\n",
        "      if num_layer!=1:\n",
        "        self.rnn=nn.RNN(embedding_size,hidden_size,num_layer,dropout=dropout,bidirectional=bidirection)\n",
        "      else:\n",
        "        self.rnn=nn.RNN(embedding_size,hidden_size,num_layer,bidirectional=bidirection)\n",
        "        \n",
        "    if bidirection:\n",
        "      self.fc=nn.Linear(hidden_size*2,output_vocab_size+3)#----------------------------------------------------\n",
        "    else:\n",
        "      self.fc=nn.Linear(hidden_size,output_vocab_size+3)\n",
        "  def forward(self,x,hidden,cell):\n",
        "\n",
        "    x=x.unsqueeze(0)  \n",
        "    embedding=self.dropout(self.embedding(x)) \n",
        "    if self.cell_type=='LSTM':  \n",
        "      output,(hidden,cell)=self.rnn(embedding,(hidden,cell)) \n",
        "    else:\n",
        "      output,hidden=self.rnn(embedding,hidden)\n",
        "      cell=None\n",
        "    prediction=self.fc(output)\n",
        "    prediction=F.log_softmax(prediction,dim=1)\n",
        "    prediction=prediction.squeeze(0)\n",
        "    \n",
        "    return prediction,hidden,cell\n",
        "    \n",
        "      \n",
        "        \n",
        "    \n",
        "class seq2seq(nn.Module):\n",
        "  def __init__(self,encoder,decoder):\n",
        "    super(seq2seq,self).__init__()\n",
        "    self.encoder=encoder\n",
        "    self.decoder=decoder\n",
        "      \n",
        "  def forward(self,source,target,teacher_forceing=0.5):\n",
        "    batch_size=source.shape[0]#64\n",
        "\n",
        "    target_len=target.shape[1]#20\n",
        "    \n",
        "    target_vocab_size=54\n",
        "    outputs=torch.zeros(target_len,batch_size,target_vocab_size+3).to(device)#--------------------------\n",
        "\n",
        "    hidden,cell=self.encoder(source)\n",
        "\n",
        "    x=target[:,0] ## for grabing <sos> token  \n",
        "\n",
        "    \n",
        "    for t in range(0,target_len):\n",
        "      pred,hidden,cell=self.decoder(x,hidden,cell)  ##or there error\n",
        "#             print(pred.shape) 64x57\n",
        "#             print(hidden.shape) 4x64x256\n",
        "      outputs[t]=pred\n",
        "      best_guess=pred.argmax(1)\n",
        "#             print(\"best\",best_guess.shape) 64 batch of each time step\n",
        "      x=target[:,t] if random.random()<teacher_forceing else best_guess\n",
        "#             print('D',target[:,t])\n",
        "    return outputs\n",
        "\n",
        "    \n",
        "        \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "QpsTYsY7wEm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bym5ANV95VWu",
        "outputId": "c488e80d-4bc5-496f-f1ee-e1722a3d16ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.23.0-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=6ab81ee7894ec57809c2cf0fe820d23faa282a9aa4f1f66dd48dd222480a6d1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.23.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "wpWAnsbI5VFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login --relogin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hscDsYmc5f4U",
        "outputId": "bc07655e-cd2b-45ff-e87f-e7b67c9178d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_configuration={'name':'EE22s037','method':'bayes',\n",
        "                     'metric':{'name':'val_acc','goal':'maximize'},\n",
        "                     'parameters':{'embedding_size':{'values':[64,128,256]},\n",
        "                                  'num_encoder_layer':{'values':[1,2,3]},\n",
        "#                                   'num_decoder_layer':{'values':[1,2,3]},\n",
        "                                  'hidden_layer_size':{'values':[64,256,512]},\n",
        "                                  'cell_type':{'values':['LSTM','GRU','RNN']},\n",
        "                                  'dropout':{'values':[0.2,0.3]},\n",
        "                                  'bidirection':{'values':[True,False]}\n",
        "                         \n",
        "                                 }\n",
        "    \n",
        "                    }\n",
        "\n",
        "\n",
        "def train():\n",
        "\n",
        "  wandb.init()\n",
        "  epochs=20\n",
        "  learning_rate=0.001\n",
        "  batch_size=64\n",
        "  \n",
        "  load_model=False\n",
        "  input_size_encoder=28\n",
        "  input_size_decoder=20\n",
        "  input_vocab_size=29\n",
        "  output_vocab_size=54\n",
        "  cell_type=wandb.config.cell_type\n",
        "  encoder_embedding_size=wandb.config.embedding_size\n",
        "  decoder_embedding_size=wandb.config.embedding_size\n",
        "  hidden_size=wandb.config.hidden_layer_size\n",
        "  num_layers=wandb.config.num_encoder_layer\n",
        "  enc_dropout=wandb.config.dropout\n",
        "  dec_dropout=wandb.config.dropout\n",
        "  bidirection=wandb.config.bidirection\n",
        "  run_name=\"ees_{}_des_{}_hs_{}_nl_{}_ed_{}_dd_{}_ct_{}_bd_{}\".format(encoder_embedding_size,decoder_embedding_size,hidden_size,num_layers,enc_dropout,dec_dropout,cell_type,bidirection)\n",
        "  print(\"run_name:\",run_name)\n",
        "  encoder_net=Encoder(input_size_encoder,encoder_embedding_size,\n",
        "                  hidden_size,num_layers,enc_dropout,input_vocab_size,bidirection,cell_type).to(device)\n",
        "  decoder_net=Decoder(input_size_decoder,decoder_embedding_size,\n",
        "                  hidden_size,output_vocab_size,num_layers,dec_dropout,bidirection,cell_type).to(device)\n",
        "\n",
        "  model=seq2seq(encoder_net,decoder_net).to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)   \n",
        "  criterion=nn.CrossEntropyLoss(ignore_index=output_vocab_size)\n",
        "  best_accuracy=0\n",
        "  train_Loss=[]\n",
        "  train_Acc=[]\n",
        "  val_Loss=[]\n",
        "  val_Acc=[]\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "  \n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss = 0.0\n",
        "    for i, (inputs, target) in enumerate(train_data_set):\n",
        "        \n",
        "      inputs=inputs.to(device)\n",
        "      target=target.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(inputs,target)\n",
        "\n",
        "      output1=output[:].reshape(-1,output.shape[2])\n",
        "\n",
        "      target1=target[:].reshape(-1)\n",
        "\n",
        "      loss = criterion(output1, target1)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "      predictions=torch.argmax(output,dim=2)#20x64\n",
        "      predictions=torch.permute(predictions,(1,0))#64x20\n",
        "\n",
        "      train_accuracy += (predictions == target).sum().item()\n",
        "      \n",
        "    train_accuracy= (train_accuracy/(len(train_data_set)*batch_size))*100 \n",
        "    train_loss=(train_loss/(len(train_data_set)*batch_size))*100\n",
        "    \n",
        "    train_Acc.append(train_accuracy)\n",
        "    train_Loss.append(train_loss)\n",
        "\n",
        "\n",
        "    # print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, epochs, running_loss/(len(train_data_set)*batch_size)))\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_accuracy=0.0\n",
        "    with torch.no_grad():\n",
        "      for i, (inputs, target) in enumerate(valid_data_set):\n",
        "        inputs=inputs.to(device)\n",
        "\n",
        "        target=target.to(device)\n",
        "\n",
        "        output = model(inputs,target)#20x65x57\n",
        "\n",
        "        output1=output[:].reshape(-1,output.shape[2])\n",
        "\n",
        "        target1=target[:].reshape(-1)\n",
        "        loss = criterion(output1, target1)\n",
        "        val_loss += loss.item()\n",
        "        predictions=torch.argmax(output,dim=2)#20x64\n",
        "        predictions=torch.permute(predictions,(1,0))#64x20\n",
        "        val_accuracy += (predictions == target).sum().item()\n",
        "      val_loss=(train_loss/(len(valid_data_set)*batch_size))*100\n",
        "      val_accuracy=(val_accuracy/(len(valid_data_set)*batch_size))*100\n",
        "      val_Acc.append(val_accuracy)\n",
        "      val_Loss.append(val_loss)\n",
        "    wandb.log({#'epoch':e,\n",
        "            'train_acc':train_accuracy,\n",
        "            'train_loss':train_loss,\n",
        "            'val_acc': val_accuracy,\n",
        "            'val_loss':val_loss       \n",
        "          })\n",
        "\n",
        "  print(\"max__train_accuracy:\",np.max(train_Acc))\n",
        "  print(\"max__validation_accuracy:\",np.max(val_Acc))\n",
        "  print(\"min_train_loss:\",np.min(train_Loss))\n",
        "  print(\"min_validation_loss:\",np.min(val_Loss))\n",
        "  plt.plot(train_Loss, 'r', label=\"Training loss\")\n",
        "  plt.plot(val_Loss, 'lime', label=\"Validation loss\")\n",
        "  plt.title(\"Training and Validation Loss vs Number of Epochs\", size=15)\n",
        "  plt.xlabel(\"Number of epochs\", size=15)\n",
        "  plt.ylabel(\"Loss\", size=15)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  plt.plot(train_Acc, 'r', label=\"Training Accuracy\")\n",
        "  plt.plot(val_Acc ,'lime', label=\"Validation Accuracy\")\n",
        "  plt.title(\"Training and Validation Accuracy vs Number of Epochs\", size=15)\n",
        "  plt.xlabel(\"Number of epochs\", size=15)\n",
        "  plt.ylabel(\"Accuracy\", size=15)\n",
        "  plt.legend()\n",
        "  plt.show()   \n",
        "  wandb.run.name = run_name\n",
        "  wandb.run.save()\n",
        "  wandb.run.finish()\n",
        "\n",
        "sweep_id=wandb.sweep(sweep=sweep_configuration,entity=\"amanvb-9213\",project='DL-assignment3')\n",
        "# sweep_id=\n",
        "wandb.agent(sweep_id,function=train,count=10)\n",
        "# wandb.agent(sweep_id,function=train,entity=\"amanvb-9213\",project='DL-assignment3')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b2BX_ql-wTRB",
        "outputId": "f2dcb7be-7b43-4bb5-c777-38546872c88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <function _WandbInit._resume_backend at 0x7fa69cc9f490> (for pre_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2990672555752099\n",
            "Create sweep with ID: voi0xux5\n",
            "Sweep URL: https://wandb.ai/amanvb-9213/DL-assignment3/sweeps/voi0xux5\n",
            "1.3056094450876117\n",
            "1.3121213312260807\n",
            "1.3186528077349067\n",
            "1.3251735824160278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oca5qcu6 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layer: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3318048263899982\n",
            "1.338411906734109\n",
            "1.3448735331185162\n",
            "1.3514222456142306\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230515_152117-oca5qcu6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amanvb-9213/DL-assignment3/runs/oca5qcu6' target=\"_blank\">vocal-sweep-1</a></strong> to <a href='https://wandb.ai/amanvb-9213/DL-assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/amanvb-9213/DL-assignment3/sweeps/voi0xux5' target=\"_blank\">https://wandb.ai/amanvb-9213/DL-assignment3/sweeps/voi0xux5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/amanvb-9213/DL-assignment3' target=\"_blank\">https://wandb.ai/amanvb-9213/DL-assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/amanvb-9213/DL-assignment3/sweeps/voi0xux5' target=\"_blank\">https://wandb.ai/amanvb-9213/DL-assignment3/sweeps/voi0xux5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/amanvb-9213/DL-assignment3/runs/oca5qcu6' target=\"_blank\">https://wandb.ai/amanvb-9213/DL-assignment3/runs/oca5qcu6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run_name: ees_128_des_128_hs_64_nl_2_ed_0.3_dd_0.3_ct_RNN_bd_True\n",
            "1.357915315311402\n",
            "1.3644536682404578\n",
            "1.3709830143488944\n",
            "1.377476894762367\n",
            "1.3839150303974748\n",
            "1.390537646599114\n",
            "1.3969672247767448\n",
            "1.403435481712222\n",
            "1.4101556884124875\n",
            "1.41668031970039\n",
            "1.4232968483120203\n",
            "1.4298033695667982\n",
            "1.4364006156101823\n",
            "1.4429384442046285\n",
            "1.449508820194751\n",
            "1.4561517611145973\n",
            "1.462649688590318\n",
            "1.469211794435978\n",
            "1.4757349155843258\n",
            "1.4822935056872666\n",
            "1.4890103600919247\n",
            "1.4955379110760987\n",
            "1.5019375258125365\n",
            "1.5084533621557057\n",
            "1.5148312808014452\n",
            "1.521337693091482\n",
            "1.5278397416695952\n",
            "1.5342843574471772\n",
            "1.5410463442094624\n",
            "1.5477069756016135\n",
            "1.5542732561007142\n",
            "1.5608623083680868\n",
            "1.567343114875257\n",
            "1.5737515478394926\n",
            "1.5802827482111752\n",
            "1.5867859022691846\n",
            "1.5934728188440204\n",
            "1.5998847908340397\n",
            "1.6063380893319843\n",
            "1.612957798875868\n",
            "1.619281039107591\n",
            "1.6258036023937166\n",
            "1.6324394759722054\n",
            "1.639092490077019\n",
            "1.6456705438904464\n",
            "1.652434594463557\n",
            "1.6592104672454298\n",
            "1.6659289947710931\n",
            "1.6726324702613056\n",
            "1.6793155418708918\n",
            "1.6858899230137467\n",
            "1.6925307661294937\n",
            "1.698930164333433\n",
            "1.7055606390349567\n",
            "1.7121422090567648\n",
            "1.7187129710800946\n",
            "1.7252567620016634\n",
            "1.7319496423006058\n",
            "1.738402040209621\n",
            "1.744971753563732\n",
            "1.7514694556593893\n",
            "1.757993711158633\n",
            "1.7644713348709047\n",
            "1.7709662695415316\n",
            "1.777463116683066\n",
            "1.7839360609650614\n",
            "1.790435199160129\n",
            "1.796801058575511\n",
            "1.803162835072726\n",
            "1.8094799532555044\n",
            "1.816084754653275\n",
            "1.8225096594542265\n",
            "1.8291607019491494\n",
            "1.835792133118957\n",
            "1.8422997733578088\n",
            "1.8487957580946388\n",
            "5.38307326938957\n",
            "1.855267396196723\n",
            "1.8617983642034233\n",
            "1.8683398016728459\n",
            "1.8748767334036531\n",
            "1.8814425002783537\n",
            "1.8879273519851267\n",
            "1.8946379818953574\n",
            "1.9011099017225208\n",
            "1.907561852131039\n",
            "1.9140362837351859\n",
            "1.9205625699833035\n",
            "1.9271561307832599\n",
            "1.9336233334615827\n",
            "1.9402592969127002\n",
            "1.946728070732206\n",
            "1.953134285286069\n",
            "1.9595375563949347\n",
            "1.9660547259263694\n",
            "1.972515842411667\n",
            "1.9790316713042557\n",
            "1.9854470039717853\n",
            "1.99186433525756\n",
            "1.998439076822251\n",
            "2.004933914169669\n",
            "2.011488775257021\n",
            "2.0179058867506683\n",
            "2.0244522830471396\n",
            "2.0309069557115436\n",
            "2.0376274934969842\n",
            "2.0441261953674257\n",
            "2.050578150898218\n",
            "2.057048700284213\n",
            "2.063527594320476\n",
            "2.069866179022938\n",
            "2.0763035053387284\n",
            "2.0828306316398084\n",
            "2.0892330347560346\n",
            "2.095687377266586\n",
            "2.1021861592307687\n",
            "2.1086720903404057\n",
            "2.115289576817304\n",
            "2.121762065216899\n",
            "2.1283858004026115\n",
            "2.134876750409603\n",
            "2.141362995374948\n",
            "2.147930001374334\n",
            "2.1544730626046658\n",
            "2.16094853496179\n",
            "2.1672926545143127\n",
            "2.173727455548942\n",
            "2.180154339876026\n",
            "2.1868246127851307\n",
            "2.193529380019754\n",
            "2.2001425004564226\n",
            "2.2066285433247685\n",
            "2.213070244528353\n",
            "2.219546399079263\n",
            "2.2260939818806946\n",
            "2.2324410346336663\n",
            "2.2388232783414423\n",
            "2.245242867618799\n",
            "2.2517751026898623\n",
            "2.258238603360951\n",
            "2.264826001599431\n",
            "2.271295650396496\n",
            "2.2779006105847657\n",
            "2.284485020674765\n",
            "2.2909371806308627\n",
            "2.2973517077043653\n",
            "2.30385282356292\n",
            "2.3103057332336903\n",
            "2.316858984529972\n",
            "2.323224921245128\n",
            "2.3297695671208203\n",
            "2.336269298568368\n",
            "2.3426672467030585\n",
            "2.349219278432429\n",
            "5.130447490140796\n",
            "2.3555827997624874\n",
            "2.362048744224012\n",
            "2.3685649568215013\n",
            "2.3751767305657268\n",
            "2.3815707596950233\n",
            "2.3880486888810992\n",
            "2.3944451534189284\n",
            "2.400979356840253\n",
            "2.4075028588995337\n",
            "2.4141854546032846\n",
            "2.420603074133396\n",
            "2.4272389644756913\n",
            "2.433686734177172\n",
            "2.4400973175652325\n",
            "2.4465763065963984\n",
            "2.4531148178502917\n",
            "2.4596802829764783\n",
            "2.4663300183601677\n",
            "2.4727922724559903\n",
            "2.4792387378402054\n",
            "2.4858273891732097\n",
            "2.492360574193299\n",
            "2.4988964600488544\n",
            "2.5053049866110086\n",
            "2.51169715821743\n",
            "2.518183938227594\n",
            "2.5246991445310414\n",
            "2.5310192368924618\n",
            "2.5375648587942123\n",
            "2.5439756154082716\n",
            "2.5504354424774647\n",
            "2.5568772526457906\n",
            "2.5632156641222537\n",
            "2.569681449793279\n",
            "2.576069821137935\n",
            "2.5825043679215014\n",
            "2.5888364920392632\n",
            "2.595448303502053\n",
            "2.6019994863308966\n",
            "2.6084639565087855\n",
            "2.6148750013671815\n",
            "2.62136445986107\n",
            "2.6278566573746502\n",
            "2.6342651415616274\n",
            "2.6407471979036927\n",
            "2.6471802103333175\n",
            "2.6535674445331097\n",
            "2.6600450496189296\n",
            "2.6667118086479604\n",
            "2.673181474208832\n",
            "2.6798033355735242\n",
            "2.686395924538374\n",
            "2.692904102150351\n",
            "2.699335776269436\n",
            "2.705671521835029\n",
            "2.7120809722691774\n",
            "2.7185056461021304\n",
            "2.7248995802365243\n",
            "2.7316203247755766\n",
            "2.738200269639492\n",
            "2.7447101091966033\n",
            "2.751302589662373\n",
            "2.7577904113568366\n",
            "2.7643156684935093\n",
            "2.7708239518105984\n",
            "2.7772196368314326\n",
            "2.7836225163191557\n",
            "2.7901662681251764\n",
            "2.7965778233483434\n",
            "2.8030817126855254\n",
            "2.809520182199776\n",
            "2.816044807434082\n",
            "2.822670120280236\n",
            "2.829113230109215\n",
            "2.8356193103827536\n",
            "2.8421666407957673\n",
            "5.126034350134432\n",
            "2.848570407833904\n",
            "2.855006744619459\n",
            "2.8613918074406683\n",
            "2.8677913760766387\n",
            "2.87422795034945\n",
            "2.8806656934320927\n",
            "2.8870885823853314\n",
            "2.8935654032975435\n",
            "2.899891289882362\n",
            "2.9065637793391943\n",
            "2.913225100841373\n",
            "2.9196304194629192\n",
            "2.9260766399092972\n",
            "2.9325144137255847\n",
            "2.9388793553225696\n",
            "2.945415960624814\n",
            "2.9519332088530064\n",
            "2.958453224040568\n",
            "2.96504459483549\n",
            "2.9715438541024923\n",
            "2.9780222438275814\n",
            "2.984594120644033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <function _WandbInit._pause_backend at 0x7fa69cc9fa30> (for post_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cn82ef7k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "eilHyJn6v02D",
        "outputId": "6c993dfa-2a3c-43cf-84a1-6031f230e281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9927befa4053>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcn82ef7k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cn82ef7k' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ZqQxRvUrkcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_best_model():\n",
        "\n",
        "  wandb.init()\n",
        "  epochs=20\n",
        "  learning_rate=0.001\n",
        "  batch_size=64\n",
        "  \n",
        "  load_model=False\n",
        "  input_size_encoder=28\n",
        "  input_size_decoder=20\n",
        "  input_vocab_size=29\n",
        "  output_vocab_size=54\n",
        "  cell_type=wandb.config.cell_type\n",
        "  encoder_embedding_size=wandb.config.embedding_size\n",
        "  decoder_embedding_size=wandb.config.embedding_size\n",
        "  hidden_size=wandb.config.hidden_layer_size\n",
        "  num_layers=wandb.config.num_encoder_layer\n",
        "  enc_dropout=wandb.config.dropout\n",
        "  dec_dropout=wandb.config.dropout\n",
        "  bidirection=wandb.config.bidirection\n",
        "  run_name=\"ees_{}_des_{}_hs_{}_nl_{}_ed_{}_dd_{}_ct_{}_bd_{}\".format(encoder_embedding_size,decoder_embedding_size,hidden_size,num_layers,enc_dropout,dec_dropout,cell_type,bidirection)\n",
        "  print(\"run_name:\",run_name)\n",
        "  encoder_net=Encoder(input_size_encoder,encoder_embedding_size,\n",
        "                  hidden_size,num_layers,enc_dropout,input_vocab_size,bidirection,cell_type).to(device)\n",
        "  decoder_net=Decoder(input_size_decoder,decoder_embedding_size,\n",
        "                  hidden_size,output_vocab_size,num_layers,dec_dropout,bidirection,cell_type).to(device)\n",
        "\n",
        "  model=seq2seq(encoder_net,decoder_net).to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)   \n",
        "  criterion=nn.CrossEntropyLoss(ignore_index=output_vocab_size)\n",
        "  best_accuracy=0\n",
        "  train_Loss=[]\n",
        "  train_Acc=[]\n",
        "  val_Loss=[]\n",
        "  val_Acc=[]\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "  \n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss = 0.0\n",
        "    for i, (inputs, target) in enumerate(train_data_set):\n",
        "        \n",
        "      inputs=inputs.to(device)\n",
        "      target=target.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(inputs,target)\n",
        "\n",
        "      output1=output[:].reshape(-1,output.shape[2])\n",
        "\n",
        "      target1=target[:].reshape(-1)\n",
        "\n",
        "      loss = criterion(output1, target1)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "      predictions=torch.argmax(output,dim=2)#20x64\n",
        "      predictions=torch.permute(predictions,(1,0))#64x20\n",
        "\n",
        "      train_accuracy += (predictions == target).sum().item()\n",
        "      \n",
        "    train_accuracy= (train_accuracy/(len(train_data_set)*batch_size))*100 \n",
        "    train_loss=(train_loss/(len(train_data_set)*batch_size))*100\n",
        "    \n",
        "    train_Acc.append(train_accuracy)\n",
        "    train_Loss.append(train_loss)\n",
        "\n",
        "\n",
        "    # print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, epochs, running_loss/(len(train_data_set)*batch_size)))\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_accuracy=0.0\n",
        "    with torch.no_grad():\n",
        "      for i, (inputs, target) in enumerate(valid_data_set):\n",
        "        inputs=inputs.to(device)\n",
        "\n",
        "        target=target.to(device)\n",
        "\n",
        "        output = model(inputs,target)#20x65x57\n",
        "\n",
        "        output1=output[:].reshape(-1,output.shape[2])\n",
        "\n",
        "        target1=target[:].reshape(-1)\n",
        "        loss = criterion(output1, target1)\n",
        "        val_loss += loss.item()\n",
        "        predictions=torch.argmax(output,dim=2)#20x64\n",
        "        predictions=torch.permute(predictions,(1,0))#64x20\n",
        "        val_accuracy += (predictions == target).sum().item()\n",
        "      val_loss=(train_loss/(len(valid_data_set)*batch_size))*100\n",
        "      val_accuracy=(val_accuracy/(len(valid_data_set)*batch_size))*100\n",
        "      val_Acc.append(val_accuracy)\n",
        "      val_Loss.append(val_loss)\n",
        "      if val_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        model_wts=copy.deepcopy(model.state_dict())\n",
        "        best_accuracy=val_accuracy\n",
        "\n",
        "  print(\"max__train_accuracy:\",np.max(train_Acc))\n",
        "  print(\"max__validation_accuracy:\",np.max(val_Acc))\n",
        "  print(\"min_train_loss:\",np.min(train_Loss))\n",
        "  print(\"min_validation_loss:\",np.min(val_Loss))\n",
        "  plt.plot(train_Loss, 'r', label=\"Training loss\")\n",
        "  plt.plot(val_Loss, 'lime', label=\"Validation loss\")\n",
        "  plt.title(\"Training and Validation Loss vs Number of Epochs\", size=15)\n",
        "  plt.xlabel(\"Number of epochs\", size=15)\n",
        "  plt.ylabel(\"Loss\", size=15)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  plt.plot(train_Acc, 'r', label=\"Training Accuracy\")\n",
        "  plt.plot(val_Acc ,'lime', label=\"Validation Accuracy\")\n",
        "  plt.title(\"Training and Validation Accuracy vs Number of Epochs\", size=15)\n",
        "  plt.xlabel(\"Number of epochs\", size=15)\n",
        "  plt.ylabel(\"Accuracy\", size=15)\n",
        "  plt.legend()\n",
        "  plt.show() \n",
        "  model.load_state_dict(model_wts)\n",
        "  return model  "
      ],
      "metadata": {
        "id": "ugKLjHqErkYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6B-ku3urkVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model=train_best_model()"
      ],
      "metadata": {
        "id": "URKTZi-2rkRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vpX1XpKyrkMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vkXIvDG1rkHr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}